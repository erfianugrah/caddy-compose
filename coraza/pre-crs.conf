# Pre-CRS configuration — loaded BEFORE OWASP CRS
# Replaces @coraza.conf-recommended with manual settings so we can
# control body processing. The key difference: we do NOT enable the
# XML body processor (rule 200000 from recommended), keeping
# REQUEST_BODY available as raw text for regex-based XXE detection.
# JSON body processor IS enabled — it doesn't interfere with XXE rules
# and is needed for CRS to properly inspect JSON payloads.
#
# Rule IDs used:
#   200001, 200002, 200003, 200006 — from @coraza.conf-recommended
#   9100001             — Socket.io exclusion
#   9100003, 9100006    — custom XXE rules
#   9100030–9100039     — heuristic bot signal rules

# ── Engine & request body settings ──────────────────────────────────
SecRequestBodyAccess On
SecRequestBodyLimit 13107200
SecRequestBodyInMemoryLimit 131072
# ProcessPartial: inspect the first 13 MB of the body, let the rest
# through uninspected. This allows large file uploads (e.g. S3/MinIO)
# while still scanning the initial portion for attacks.
# Use "Reject" instead to hard-block oversized bodies.
SecRequestBodyLimitAction ProcessPartial

# ── JSON body processor (from @coraza.conf-recommended) ─────────────
# Initiate JSON processor for application/json content type
SecRule REQUEST_HEADERS:Content-Type "^application/json" \
    "id:'200001',phase:1,t:none,t:lowercase,pass,nolog,ctl:requestBodyProcessor=JSON"

# JSON processor for +json subtypes (e.g. application/vnd.api+json)
SecRule REQUEST_HEADERS:Content-Type "^application/[a-z0-9.-]+[+]json" \
    "id:'200006',phase:1,t:none,t:lowercase,pass,nolog,ctl:requestBodyProcessor=JSON"

# NOTE: XML body processor (rule 200000) is intentionally OMITTED.
# It would consume REQUEST_BODY into an XML parse tree, making
# regex-based XXE detection in rules 9100003/9100006 ineffective.

# ── Request body error handling (from @coraza.conf-recommended) ─────
# Deny requests with unparseable bodies (catches malformed POST data)
SecRule REQBODY_ERROR "!@eq 0" \
    "id:'200002',phase:2,t:none,log,deny,status:400,\
    msg:'Failed to parse request body.',\
    logdata:'%{reqbody_error_msg}',severity:2"

# Deny requests failing multipart strict validation (catches evasion)
SecRule MULTIPART_STRICT_ERROR "!@eq 0" \
    "id:'200003',phase:2,t:none,log,deny,status:400,\
    msg:'Multipart request body failed strict validation.'"

# ── Response body settings ──────────────────────────────────────────
# Disabled: response body inspection buffers entire responses, which breaks
# large JSON APIs (e.g. radarr /api/v3/movie returning 500+ entries).
# Data leak detection (outbound rules) is less useful for a homelab.
SecResponseBodyAccess Off

# ── Persistent data directory ───────────────────────────────────────
SecDataDir /tmp/

# ── Socket.io exclusion ─────────────────────────────────────────────
# Socket.io long-polling sends text/plain bodies, which CRS rule 920420
# rejects (content type not in allowed list). Skip that rule for socket.io paths.
SecRule REQUEST_URI "@beginsWith /socket.io/" \
    "id:9100001,\
    phase:1,\
    pass,\
    nolog,\
    ctl:ruleRemoveById=920420"

# ── Custom XXE rules ────────────────────────────────────────────────
# These rely on raw REQUEST_BODY (no XML processor), which is why
# we omit rule 200000 above.

# XXE: DOCTYPE/ENTITY with SYSTEM or PUBLIC in request body
SecRule REQUEST_BODY "@rx (?i:<!(?:DOCTYPE|ENTITY)[^>]*(?:SYSTEM|PUBLIC))" \
    "id:9100003,\
    phase:2,\
    deny,\
    status:403,\
    log,\
    msg:'XXE: DOCTYPE/ENTITY with SYSTEM or PUBLIC detected in body',\
    tag:'attack-xxe',\
    tag:'custom-rules',\
    severity:'CRITICAL'"

# XXE: parameter entities (% in ENTITY declaration)
SecRule REQUEST_BODY "@rx (?i:<!ENTITY\s+%)" \
    "id:9100006,\
    phase:2,\
    deny,\
    status:403,\
    log,\
    msg:'XXE: parameter entity detected in body',\
    tag:'attack-xxe',\
    tag:'custom-rules',\
    severity:'CRITICAL'"

# ── Heuristic Bot Signals ───────────────────────────────────────────
# Detect suspicious request characteristics that individually are weak
# signals but combine via CRS anomaly scoring to catch automated tools.
# Each signal adds to tx.anomaly_score_pl1 (CRS's native scoring var).
# Multiple signals on one request will breach the inbound threshold.
#
# Health-check and internal paths are excluded via chained conditions
# to avoid false positives on monitoring probes and Caddy internals.

# --- Heuristic: missing Accept header (+2 anomaly) ---
# Real browsers always send Accept. Its absence suggests a script or
# scanner. Excluded: /api/health (monitoring), waf-api internal.
SecRule &REQUEST_HEADERS:Accept "@eq 0" \
    "id:9100030,\
    phase:1,\
    pass,\
    t:none,\
    nolog,\
    setvar:'tx.anomaly_score_pl1=+2',\
    msg:'Heuristic: missing Accept header',\
    tag:'heuristic',\
    tag:'custom-rules',\
    chain"
    SecRule REQUEST_URI "!@beginsWith /api/health" "t:none"

# --- Heuristic: HTTP/1.0 protocol (+2 anomaly) ---
# Modern clients use HTTP/1.1 or HTTP/2. HTTP/1.0 is almost exclusively
# used by old scripts, scanners, and vulnerability assessment tools.
SecRule REQUEST_PROTOCOL "@streq HTTP/1.0" \
    "id:9100031,\
    phase:1,\
    pass,\
    t:none,\
    nolog,\
    setvar:'tx.anomaly_score_pl1=+2',\
    msg:'Heuristic: HTTP/1.0 protocol',\
    tag:'heuristic',\
    tag:'custom-rules'"

# --- Heuristic: known scanner User-Agent (drop) ---
# Any client explicitly identifying as a scanner tool is not a false
# positive. Uses drop (connection reset) instead of deny — more hostile
# than a clean 403, wastes scanner time on connection errors.
# UA list loaded from external file for easy maintenance.
SecRule REQUEST_HEADERS:User-Agent "@pmFromFile /etc/caddy/coraza/scanner-useragents.txt" \
    "id:9100032,\
    phase:1,\
    drop,\
    log,\
    msg:'Heuristic: known scanner User-Agent',\
    logdata:'%{REQUEST_HEADERS.User-Agent}',\
    tag:'heuristic',\
    tag:'scanner',\
    tag:'custom-rules',\
    severity:'CRITICAL'"

# --- Heuristic: empty User-Agent (+3 anomaly) ---
# CRS 920320 partially covers this, but with a lower score. We add
# extra weight since empty UA is a strong bot signal. Not blocking
# outright since some legitimate API clients omit it.
SecRule &REQUEST_HEADERS:User-Agent "@eq 0" \
    "id:9100033,\
    phase:1,\
    pass,\
    t:none,\
    nolog,\
    setvar:'tx.anomaly_score_pl1=+3',\
    msg:'Heuristic: empty or missing User-Agent',\
    tag:'heuristic',\
    tag:'custom-rules'"

# --- Heuristic: missing Referer on non-API GET (+1 anomaly) ---
# Direct URL hits without Referer on non-API endpoints suggest scanning.
# Low score (+1) because bookmarks and direct navigation also lack Referer.
# Excluded: API paths, health checks, favicon, robots.txt.
SecRule REQUEST_METHOD "@streq GET" \
    "id:9100034,\
    phase:1,\
    pass,\
    t:none,\
    nolog,\
    setvar:'tx.anomaly_score_pl1=+1',\
    msg:'Heuristic: missing Referer on non-API GET',\
    tag:'heuristic',\
    tag:'custom-rules',\
    chain"
    SecRule &REQUEST_HEADERS:Referer "@eq 0" "t:none,chain"
    SecRule REQUEST_URI "!@rx ^/(?:api/|favicon|robots\.txt)" "t:none"
